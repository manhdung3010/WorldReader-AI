# main.py
from api.recommendation_api import RecommendationAPI
from data.data_loader import DataLoader
from data.preprocessor import DataPreprocessor
from models.tfidf_model import TfidfEmbeddingModel
from models.faiss_index import FaissIndexModel
from config.settings import Config
import pandas as pd

# H·ªá th·ªëng g·ª£i √Ω ch√≠nh
class ProductRecommendationSystem:
    """H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m t·ªïng th·ªÉ k·∫øt h·ª£p t·∫•t c·∫£ c√°c th√†nh ph·∫ßn"""
    
    def __init__(self):
        self.data_loader = DataLoader()
        self.preprocessor = DataPreprocessor()
        self.embedding_model = None
        self.index_model = None
        self.products_df = None
        self.processed_df = None
        self.is_trained = False
    
    def load_data(self, source='database', **kwargs):
        """T·∫£i d·ªØ li·ªáu t·ª´ ngu·ªìn ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
        if source == 'database':
            limit = kwargs.get('limit', 1000)
            self.products_df = self.data_loader.load_from_database(limit=limit)
        elif source == 'csv':
            file_path = kwargs.get('file_path')
            if not file_path:
                raise ValueError("C·∫ßn ch·ªâ ƒë·ªãnh file_path cho ngu·ªìn CSV")
            self.products_df = self.data_loader.load_from_csv(file_path)
        else:
            raise ValueError(f"Ngu·ªìn d·ªØ li·ªáu kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {source}")
        
        print(f"üîç ƒê√£ t·∫£i {len(self.products_df)} s·∫£n ph·∫©m t·ª´ {source}")
        return self.products_df
    
    def load_product_by_id(self, product_id):
        """T·∫£i s·∫£n ph·∫©m theo ID"""
        product = self.data_loader.load_by_ids([product_id])
        if product.empty:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m c√≥ ID: {product_id}")
            return None
        return product
    
    def preprocess_data(self, data=None):
        """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu s·∫£n ph·∫©m"""
        df_to_process = data if data is not None else self.products_df
        
        if df_to_process is None:
            raise ValueError("Ch∆∞a t·∫£i d·ªØ li·ªáu s·∫£n ph·∫©m")
        
        processed = self.preprocessor.prepare_product_data(df_to_process)
        
        if data is None:
            self.processed_df = processed
            print(f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(self.processed_df)} s·∫£n ph·∫©m")
        
        return processed
    
    def build_embedding_model(self, model_type='tfidf', **kwargs):
        """X√¢y d·ª±ng m√¥ h√¨nh nh√∫ng"""
        if model_type == 'tfidf':
            max_features = kwargs.get('max_features', Config.EMBEDDING_SIZE)
            ngram_range = kwargs.get('ngram_range', (1, 2))
            language = kwargs.get('language', 'english')
            
            self.embedding_model = TfidfEmbeddingModel(
                max_features=max_features,
                ngram_range=ngram_range,
                language=language
            )
        else:
            raise ValueError(f"Lo·∫°i m√¥ h√¨nh nh√∫ng kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {model_type}")
        
        return self.embedding_model
    
    def build_index_model(self, index_type='faiss'):
        """X√¢y d·ª±ng m√¥ h√¨nh ch·ªâ m·ª•c"""
        if index_type == 'faiss':
            self.index_model = FaissIndexModel(embedding_model=self.embedding_model)
        else:
            raise ValueError(f"Lo·∫°i m√¥ h√¨nh ch·ªâ m·ª•c kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {index_type}")
        
        return self.index_model
    
    def train(self, **kwargs):
        """Hu·∫•n luy·ªán to√†n b·ªô h·ªá th·ªëng g·ª£i √Ω"""
        print("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán h·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m...")
        
        # Tham s·ªë hu·∫•n luy·ªán
        source = kwargs.get('source', 'database')
        limit = kwargs.get('limit', 1000)
        model_type = kwargs.get('model_type', 'tfidf')
        index_type = kwargs.get('index_type', 'faiss')
        max_features = kwargs.get('max_features', Config.EMBEDDING_SIZE)
        
        # 1. T·∫£i d·ªØ li·ªáu
        self.load_data(source=source, limit=limit)
        
        # 2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
        self.preprocess_data()
        
        # 3. X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh nh√∫ng
        self.build_embedding_model(
            model_type=model_type, 
            max_features=max_features
        )
        self.embedding_model.train(self.processed_df)
        
        # 4. X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh ch·ªâ m·ª•c
        self.build_index_model(index_type=index_type)
        self.index_model.train()
        
        self.is_trained = True
        print("‚úÖ ƒê√£ ho√†n th√†nh hu·∫•n luy·ªán h·ªá th·ªëng!")
        return self
    
    def update_with_product(self, product_data):
        """C·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi m·ªôt s·∫£n ph·∫©m m·ªõi ho·∫∑c ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t"""
        # Ki·ªÉm tra xem h·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ch∆∞a
        if not self.is_trained:
            print("‚ùì H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. ƒêang kh·ªüi t·∫°o hu·∫•n luy·ªán...")
            return self.train()
        
        product_id = product_data.iloc[0]['id'] if isinstance(product_data, pd.DataFrame) else product_data['id']
        print(f"üîÑ C·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi s·∫£n ph·∫©m ID: {product_id}")
        
        # Chuy·ªÉn ƒë·ªïi sang DataFrame n·∫øu c·∫ßn
        if not isinstance(product_data, pd.DataFrame):
            product_data = pd.DataFrame([product_data])
        
        # Ti·ªÅn x·ª≠ l√Ω s·∫£n ph·∫©m m·ªõi
        processed_product = self.preprocess_data(product_data)
        
        # C·∫≠p nh·∫≠t m√¥ h√¨nh nh√∫ng v·ªõi s·∫£n ph·∫©m m·ªõi
        self.embedding_model.update(processed_product)
        
        # C·∫≠p nh·∫≠t m√¥ h√¨nh ch·ªâ m·ª•c
        self.index_model.update()
        
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi s·∫£n ph·∫©m ID: {product_id}")
        return True
    
    def update_with_products_batch(self, products_df):
        """C·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi nhi·ªÅu s·∫£n ph·∫©m c√πng l√∫c"""
        # Ki·ªÉm tra xem h·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ch∆∞a
        if not self.is_trained:
            print("‚ùì H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. ƒêang kh·ªüi t·∫°o hu·∫•n luy·ªán...")
            return self.train()
        
        print(f"üîÑ C·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi {len(products_df)} s·∫£n ph·∫©m m·ªõi")
        
        # Ti·ªÅn x·ª≠ l√Ω c√°c s·∫£n ph·∫©m m·ªõi
        processed_products = self.preprocess_data(products_df)
        
        # C·∫≠p nh·∫≠t m√¥ h√¨nh nh√∫ng v·ªõi c√°c s·∫£n ph·∫©m m·ªõi
        self.embedding_model.update(processed_products)
        
        # C·∫≠p nh·∫≠t m√¥ h√¨nh ch·ªâ m·ª•c
        self.index_model.update()
        
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t h·ªá th·ªëng v·ªõi {len(products_df)} s·∫£n ph·∫©m m·ªõi")
        return True
    
    def get_recommendations(self, product_id, k=None):
        """L·∫•y c√°c s·∫£n ph·∫©m t∆∞∆°ng t·ª± cho m·ªôt s·∫£n ph·∫©m"""
        if not self.is_trained:
            raise ValueError("H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
        
        k = k or Config.DEFAULT_K
        return self.index_model.get_recommendations(product_id, k)
    
    def get_recommendations_batch(self, product_ids, k=None):
        """L·∫•y ƒë·ªÅ xu·∫•t cho nhi·ªÅu s·∫£n ph·∫©m c√πng l√∫c"""
        if not self.is_trained:
            raise ValueError("H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán")
        
        k = k or Config.DEFAULT_K
        return self.index_model.get_recommendations_batch(product_ids, k)
    
def main():
    """H√†m ch√≠nh ƒë·ªÉ kh·ªüi ch·∫°y h·ªá th·ªëng"""
    # Kh·ªüi t·∫°o h·ªá th·ªëng g·ª£i √Ω
    recommendation_system = ProductRecommendationSystem()
    
    # Hu·∫•n luy·ªán h·ªá th·ªëng
    recommendation_system.train(limit=5000)
    
    # Kh·ªüi t·∫°o v√† ch·∫°y API
    api = RecommendationAPI(recommendation_system)
    api.run()

if __name__ == "__main__":
    main()